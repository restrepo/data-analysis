{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for DOI and DOI references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load modules and define functions. To load wosplus the `drive.cfg` must be defined first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "faltantes_udea.csv=14UKfewQ_5vitPkKIUZu_EBmRrUpbWvsj8SGVkVrg6TM\n",
    "udea_dois_api.xlsx=1f-ZWbXwqwb0oXW5bBKqa_GqhzxWWHeXM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modules\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import requests\n",
    "import wosplus as wp\n",
    "import re\n",
    "\n",
    "# new functions\n",
    "get_close_matches_Levenshtein=wp.get_close_matches_Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_unidecode_keep_alphanumeric__space(s):\n",
    "    import unidecode\n",
    "    import re\n",
    "    return unidecode.unidecode( re.sub( '([^\\s\\w])+', '',s ) ).lower()\n",
    "\n",
    "def backwards_comptibility_titles(check_text,check_mesagges_key,similarity,kwargs,item):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        check_text=None: only value of title='value' implemented\n",
    "        check_mesagges_key=None: only 'title' key implemented\n",
    "        similarity=0.6: See backwards_comptibility_titles(...) for details\n",
    "        kwargs: Cross ref query API options\n",
    "        item: Cross refs dictionary (json) output\n",
    "        \n",
    "    Compare kwargs['title']  and item['title'][0] with a similarity cutoff\n",
    "    and return boolean\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    titles_match=False\n",
    "    if not check_text:\n",
    "        try:\n",
    "            check_text=kwargs.get('title').lower()\n",
    "        except AttributeError:\n",
    "            check_text=None\n",
    "        else:\n",
    "            check_text=str(check_text) # Be sure that is string\n",
    "\n",
    "    if not check_mesagges_key:\n",
    "        check_mesagges_key='title' #'container-title'\n",
    "\n",
    "    if check_mesagges_key=='title':    \n",
    "        try:\n",
    "            item_title=item[check_mesagges_key][0]\n",
    "        except KeyError:\n",
    "            item_title=None\n",
    "        if type(item_title)==str:\n",
    "            item_title=lower_unidecode_keep_alphanumeric__space(item_title)\n",
    "\n",
    "        if check_text: # Is already an string or None!\n",
    "            check_text=lower_unidecode_keep_alphanumeric__space(check_text)\n",
    "\n",
    "            chk=get_close_matches_Levenshtein(check_text,item_title,n=1,cutoff=similarity)\n",
    "            if chk: # Not empty if cutoff >= similarity\n",
    "                titles_match=True\n",
    "    else:\n",
    "        sys.exit('ERROR {}, not yet implemented',check_mesagges_key)\n",
    "        \n",
    "    return titles_match\n",
    "\n",
    "def get_doi(DOI=None, #order does not matter\n",
    "            backwards_compatibility=True, #If falste return full dictionary and ignore next options ====\n",
    "            check_text=None,\n",
    "            check_mesagges_key=None,\n",
    "            similarity=0.6,\n",
    "            JSON=False, # END of backwards_compatibility options ===============================\n",
    "            **kwargs # CrossRef query API options: https://github.com/CrossRef/rest-api-doc#field-queries\n",
    "           ):\n",
    "    '''\n",
    "    For DOI=None (Default):\n",
    "        \n",
    "        Use the API for queries of CrossRef: \n",
    "        \n",
    "        https://github.com/CrossRef/rest-api-doc#field-queries\n",
    "        \n",
    "        in **kwargs\n",
    "        \n",
    "        Example kwargs:\n",
    "        title='room at the bottom', author='richard feynman', ...\n",
    "        \n",
    "    For DOI:\n",
    "        \n",
    "        Search for a DOI and get the full metadata info (including references!). \n",
    "        \n",
    "        Use the API for queries of CrossRef in **kwargs\n",
    "        \n",
    "        Example kwargs: title, author,...\n",
    "           \n",
    "    BACKWARDS COMPATIBILITY: Returns only matching DOI if titles are not similar! ============\n",
    "        backwards_compatibility=True, #If falste return full dictionary and ignore next options ====\n",
    "        check_text=None: only value of title='value' implemented\n",
    "        check_mesagges_key=None: only 'title' key implemented\n",
    "        similarity=0.6: See backwards_comptibility_titles(...) for details\n",
    "        JSON=False: Returns only DOI if titles does not match\n",
    "\n",
    "        The checking is doing by comparing check_text with the check_mesagges_key from the full info.\n",
    "        By default the given 'title' is used for the check.\n",
    "        \n",
    "        The checking is doing by removing all the non-alphanumeric characters but keeping spaces.\n",
    "        Also with lower and unidecode (see: lower_unidecode_keep_alphanumeric__space)\n",
    "        \n",
    "        See: backwards_comptibility_titles(...) for details\n",
    "        ==========================================================================\n",
    "    \n",
    "    EXAMPLES:\n",
    "        * get_doi(title='room at the bottom', author='richard feynman')\n",
    "        * get_doi('10.1103/physrevd.87.095010')          \n",
    "    '''\n",
    "    import re\n",
    "    import requests\n",
    "    import time\n",
    "    import random\n",
    "    #DEBUG\n",
    "    #print(kwargs)\n",
    "        \n",
    "    query='https://api.crossref.org/works'\n",
    "    if DOI:\n",
    "        query=query+'/'+DOI\n",
    "    else:\n",
    "        query=query+'?'\n",
    "        for k in kwargs.keys():\n",
    "            q=kwargs[k]\n",
    "            if type(q)==str:\n",
    "                q=re.sub('\\s+','+',q)\n",
    "                query=query+'query.{}={}&'.format(k, q )\n",
    "                \n",
    "        query=re.sub('\\&$','',query) # drop the last &\n",
    "        \n",
    "    #query is either a /DOI or a ?search of **kwargs\n",
    "    \n",
    "    #DEBUG\n",
    "    #print(query)\n",
    "    \n",
    "    r=requests.get(query)\n",
    "    try:\n",
    "        item=r.json()['message']\n",
    "        if item.get('items'): # It is a list a items orded by score. Pick the first one:\n",
    "            #TODO: loop the list\n",
    "            item=item['items']#[0]\n",
    "        elif not DOI:\n",
    "            item=[item]\n",
    "    except:\n",
    "        item={}\n",
    "        \n",
    "    #BACKWARDS compatibility====================\n",
    "    if not DOI and backwards_compatibility: # returns only matched DOI if titles are not similar\n",
    "        for ii in range(len(item)):\n",
    "            check_titles=backwards_comptibility_titles(check_text,check_mesagges_key,similarity,kwargs,item[ii])\n",
    "\n",
    "            if check_titles:\n",
    "                if ii>0:\n",
    "                    f=open('cr.log','a')\n",
    "                    f.write('WRONG order at: {}\\n'.format(i))\n",
    "                    f.close()\n",
    "                item=item[ii]\n",
    "                break        \n",
    "                \n",
    "        #check_titles=backwards_comptibility_titles(check_text,check_mesagges_key,similarity,kwargs,item)\n",
    "        if not JSON and not check_titles: #if JSON=True force full item output\n",
    "            try:\n",
    "                item=item[ii]['DOI']\n",
    "            except KeyError:\n",
    "                item=''\n",
    "    #==============================================  \n",
    "    \n",
    "    time.sleep( random.randint(1,3) ) # Avoids robots.txt\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run articles\n",
    "We need a pandas DF of articles with at least the Title and journal information. Currenly only the Title is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua=wp.read_drive_excel('faltantes_udea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ua.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare search columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ua['title']=ua.TITULO.str.lower().map(unidecode.unidecode)\n",
    "ua['journal']=ua.REVISTA.str.lower().map(unidecode.unidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583\r"
     ]
    }
   ],
   "source": [
    "similarity=0.9\n",
    "#LOG FILE=====\n",
    "# clean log file\n",
    "logfile='kkk.txt'\n",
    "f=open(logfile,'w')\n",
    "f.write('')\n",
    "f.close()\n",
    "#=============\n",
    "#DEBUG------------\n",
    "#i=3\n",
    "#if True:\n",
    "#----------\n",
    "for i in ua.index:\n",
    "    #LOG FILE========\n",
    "    f=open(logfile,'a')\n",
    "    f.write('{}\\n'.format(i)) # check from the terminal with: tail -f kkk.txt\n",
    "    f.close()\n",
    "    #================\n",
    "    j=get_doi(title=ua.loc[i,'title'],similarity=similarity)\n",
    "    #Get references\n",
    "    refs=''\n",
    "    print(i,end='\\r')\n",
    "    try:\n",
    "        for refd in j['reference']:\n",
    "            sep=';'\n",
    "            refs=refs+refd['DOI']+sep\n",
    "            \n",
    "        refs=re.sub('{}$'.format(sep),'',refs) #drop the last sep\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "    try: \n",
    "        ua.loc[i,'DOI']=j['DOI']\n",
    "        ua.loc[i,'CR_title']=j['title'][0]\n",
    "    except:\n",
    "        ua.loc[i,'DOI']=''\n",
    "        if not j:\n",
    "            ua.loc[i,'Failed']='Yes'\n",
    "\n",
    "    ua.loc[i,'REFS']=refs \n",
    "    ( ua.drop(['title','journal'],axis='columns').fillna('') ).to_excel('udea_dois_api_loop.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save file with results\n",
    "And upload to Google Drive (see `drive.cfg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua.drop(['title','journal'],axis='columns').to_excel('udea_dois_api.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover file with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr=wp.read_drive_excel('udea_dois_api.xlsx')\n",
    "dfr=dfr.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDINST</th>\n",
       "      <th>INST</th>\n",
       "      <th>CVEREVTIT</th>\n",
       "      <th>ANIO</th>\n",
       "      <th>IDREV</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>VOLUMEN</th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>PAIS</th>\n",
       "      <th>TITULO</th>\n",
       "      <th>REVISTA</th>\n",
       "      <th>DOI</th>\n",
       "      <th>REFS</th>\n",
       "      <th>CR_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15344</td>\n",
       "      <td>Universidad de Antioquia</td>\n",
       "      <td>396742056003</td>\n",
       "      <td>2014</td>\n",
       "      <td>3967</td>\n",
       "      <td>1980-5411</td>\n",
       "      <td>42056</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Sacrificio cortoplacista adaptativo 2opt (SCA_2opt): Una heurística inspirada en el pensamiento sistémico</td>\n",
       "      <td>Production</td>\n",
       "      <td>10.1590/s0103-65132013005000033</td>\n",
       "      <td>10.1109/5326.725338;</td>\n",
       "      <td>Sacrificio cortoplacista adaptativo 2opt (SCA_2opt): Una heurística inspirada en el pensamiento sistémico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15344</td>\n",
       "      <td>Universidad de Antioquia</td>\n",
       "      <td>219130127012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2191</td>\n",
       "      <td>1982-5765</td>\n",
       "      <td>30127</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>DISTINTAS LECTURAS DE LA PREGUNTA COMO MEDIACIÓN DIDÁCTICA PARA LA TRADUCCIÓN DE SABERES EN LA EDUCACIÓN SUPERIOR O ACERCA DE UN ESTADO EN CUESTIÓN</td>\n",
       "      <td>Avaliação: Revista da Avaliação da Educação Superior</td>\n",
       "      <td>10.1590/s1414-40772014000100012</td>\n",
       "      <td>10.1023/A:1004138810465;</td>\n",
       "      <td>Distintas lecturas de la pregunta como mediación didáctica para la traducción de saberes en la educación superior o acerca de un estado en cuestión</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDINST                      INST     CVEREVTIT  ANIO  IDREV       ISSN  \\\n",
       "0   15344  Universidad de Antioquia  396742056003  2014   3967  1980-5411   \n",
       "1   15344  Universidad de Antioquia  219130127012  2014   2191  1982-5765   \n",
       "\n",
       "   IDNUM VOLUMEN NUMERO    PAIS  \\\n",
       "0  42056      24      1  Brasil   \n",
       "1  30127      19      1  Brasil   \n",
       "\n",
       "                                                                                                                                                TITULO  \\\n",
       "0                                            Sacrificio cortoplacista adaptativo 2opt (SCA_2opt): Una heurística inspirada en el pensamiento sistémico   \n",
       "1  DISTINTAS LECTURAS DE LA PREGUNTA COMO MEDIACIÓN DIDÁCTICA PARA LA TRADUCCIÓN DE SABERES EN LA EDUCACIÓN SUPERIOR O ACERCA DE UN ESTADO EN CUESTIÓN   \n",
       "\n",
       "                                                REVISTA  \\\n",
       "0                                            Production   \n",
       "1  Avaliação: Revista da Avaliação da Educação Superior   \n",
       "\n",
       "                               DOI                      REFS  \\\n",
       "0  10.1590/s0103-65132013005000033      10.1109/5326.725338;   \n",
       "1  10.1590/s1414-40772014000100012  10.1023/A:1004138810465;   \n",
       "\n",
       "                                                                                                                                              CR_title  \n",
       "0                                            Sacrificio cortoplacista adaptativo 2opt (SCA_2opt): Una heurística inspirada en el pensamiento sistémico  \n",
       "1  Distintas lecturas de la pregunta como mediación didáctica para la traducción de saberes en la educación superior o acerca de un estado en cuestión  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr[dfr.REFS!='']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return back to [Pandas](./Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
